{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9187c0-45a2-4088-991e-0a9fb86edf9f",
   "metadata": {},
   "source": [
    "Explore how the collect() operation works in PySpark using a dataset with basic RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f58c4f9-30cd-4d33-b9f4-cd815b78a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# Point to Java & Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Progra~1/Java/jdk1.8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:/spark/spark-3.5.7-bin-hadoop3-scala2.13\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"   # if you installed winutils here\n",
    "os.environ[\"PATH\"] += \";C:/spark/spark-3.5.7-bin-hadoop3-scala2.13/bin;C:/hadoop/bin\"\n",
    "\n",
    "# Initialize findspark\n",
    "findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Now build SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV_RDD_Example\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedb687-68fb-4568-af99-c13992370e7a",
   "metadata": {},
   "source": [
    "ðŸ“Š Dataset Overview\n",
    "\n",
    "\n",
    "       --Total Records: 50 students\n",
    "\n",
    "       --Columns: 7 â†’ id, name, age, gender, math, science, english\n",
    "\n",
    "       --No missing values\n",
    "\n",
    "\n",
    "ðŸ‘¥ Demographics\n",
    "\n",
    "       --Age: 18 â€“ 25 years (average â‰ˆ 21.5)\n",
    "\n",
    "       --Gender: 29 Female, 21 Male\n",
    "\n",
    "ðŸ“š Academic Performance\n",
    "\n",
    "*****Math:\n",
    "\n",
    "       --Range: 40 â€“ 100\n",
    "\n",
    "       --Mean: 68.9\n",
    "\n",
    "       --Std. Dev.: 17.6 (high variation)\n",
    "\n",
    "*****Science:\n",
    "\n",
    "       --Range: 44 â€“ 99\n",
    "\n",
    "       --Mean: 70.2\n",
    "\n",
    "       --Std. Dev.: 14.6 (moderate variation)\n",
    "\n",
    "*****English:\n",
    "\n",
    "       --Range: 42 â€“ 100\n",
    "\n",
    "       --Mean: 69.4\n",
    "\n",
    "       --Std. Dev.: 18.7 (highest variation)\n",
    "\n",
    "Key Insights\n",
    "\n",
    "       --Science is the strongest subject on average.\n",
    "\n",
    "       --English has the most variation in performance.\n",
    "\n",
    "       --Students perform differently across subjects (not uniform).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217d7728-4c5e-4767-9b69-54eb33b32d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext\n",
    "\n",
    "# # Initialize SparkContext\n",
    "# sc = SparkContext(\"local\", \"CSV_RDD_Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4439b426-40b4-4b82-a34c-351b259f11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CSV file (students.csv must be in same folder as notebook)\n",
    "data = sc.textFile(\"students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458bb825-5c0c-40ed-9911-8d7c083b87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove header\n",
    "header = data.first()\n",
    "rows = data.filter(lambda line: line != header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb2ae2a-8cd4-40e3-9e1b-b7e20007eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by comma\n",
    "split_rdd = rows.map(lambda line: line.split(\",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b50131-d33f-4118-b7e1-3a645c19b39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Student Dataset (first 10 rows) ===\n",
      "['1', 'Alice', '20', 'F', '66', '92', '44']\n",
      "['2', 'Bob', '20', 'M', '82', '52', '77']\n",
      "['3', 'Charlie', '22', 'F', '43', '57', '76']\n",
      "['4', 'David', '19', 'M', '95', '69', '46']\n",
      "['5', 'Eva', '19', 'F', '62', '44', '96']\n",
      "['6', 'Frank', '22', 'F', '70', '78', '94']\n",
      "['7', 'Grace', '24', 'F', '67', '66', '93']\n",
      "['8', 'Henry', '21', 'F', '53', '82', '60']\n",
      "['9', 'Ivy', '19', 'M', '64', '52', '46']\n",
      "['10', 'Jack', '19', 'F', '44', '59', '60']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Student Dataset (first 10 rows) ===\")\n",
    "for row in split_rdd.take(10):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "232620a0-35ef-4fe9-8ac4-cc7a95406f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fields into structured format\n",
    "students_rdd = split_rdd.map(lambda x: (int(x[0]), x[1], int(x[2]), x[3], int(x[4]), int(x[5]), int(x[6])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810e7581-93b3-4c9f-803d-692dc9100254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average marks for each student\n",
    "avg_marks_rdd = students_rdd.map(lambda x: (x[1], (x[4] + x[5] + x[6]) / 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5472a1ec-9078-4fbd-90c1-8dc2d8d2c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter students who scored avg >= 75\n",
    "passed_rdd = avg_marks_rdd.filter(lambda x: x[1] >= 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "584cf09d-b3e5-4688-8397-76ab39615582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort students by avg marks (descending)\n",
    "sorted_passed_rdd = passed_rdd.sortBy(lambda x: x[1], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914672ca-5b25-4eed-be18-739c846c2ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Students with Average >= 75 ===\n",
      "Name: Leo, Avg Marks: 88.00\n",
      "Name: Olivia, Avg Marks: 88.00\n",
      "Name: Rita, Avg Marks: 86.67\n",
      "Name: Kathy, Avg Marks: 81.67\n",
      "Name: George, Avg Marks: 81.67\n",
      "Name: Frank, Avg Marks: 80.67\n",
      "Name: Oscar, Avg Marks: 80.00\n",
      "Name: Uma, Avg Marks: 78.33\n",
      "Name: Kyle, Avg Marks: 78.33\n",
      "Name: Matt, Avg Marks: 78.33\n",
      "Name: Tina, Avg Marks: 76.00\n",
      "Name: Victor, Avg Marks: 75.67\n",
      "Name: Grace, Avg Marks: 75.33\n",
      "Name: Mona, Avg Marks: 75.00\n",
      "Name: Will, Avg Marks: 75.00\n"
     ]
    }
   ],
   "source": [
    "# Collect results\n",
    "results = sorted_passed_rdd.collect()\n",
    "print(\"\\n=== Students with Average >= 75 ===\")\n",
    "for student in results:\n",
    "    print(f\"Name: {student[0]}, Avg Marks: {student[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db24ddb1-5a97-4619-9c9b-171cbb2485b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of students who passed: 15\n"
     ]
    }
   ],
   "source": [
    "# Count how many passed\n",
    "count_passed = passed_rdd.count()\n",
    "print(\"\\nNumber of students who passed:\", count_passed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e659feca-3ed8-4e8c-b0ea-9c5a8faf367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topper: ('Olivia', 88.0)\n"
     ]
    }
   ],
   "source": [
    "# Find topper\n",
    "topper = passed_rdd.reduce(lambda a, b: a if a[1] > b[1] else b)\n",
    "print(\"Topper:\", topper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cede236a-c028-4af0-b5c7-c4337c6eab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 Passed Students:\n",
      "[('Frank', 80.66666666666667), ('Grace', 75.33333333333333), ('Kathy', 81.66666666666667), ('Leo', 88.0), ('Mona', 75.0)]\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 passed students\n",
    "print(\"\\nFirst 5 Passed Students:\")\n",
    "print(passed_rdd.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb88088-0019-4e80-a990-5ddf8bcfec93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d23e8329-1f1c-4b54-8ccd-3f489e984247",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "*****Spark Context setup (sc).\n",
    "\n",
    "*****Loading Dataset:\n",
    "\n",
    "        data = sc.textFile(\"students.csv\")\n",
    "\n",
    "*****Preprocessing:\n",
    "\n",
    "        --Removed header row.\n",
    "\n",
    "        --Split lines into fields.\n",
    "\n",
    "*****Transformations:\n",
    "\n",
    "        --map() â†’ convert rows into structured format.\n",
    "\n",
    "        --filter() â†’ apply conditions (e.g., scores/age-based filtering).\n",
    "\n",
    "        --flatMap() â†’ expand data where needed.\n",
    "\n",
    "*****Actions:\n",
    "\n",
    "        --collect() â†’ retrieve all records.\n",
    "\n",
    "        --count() â†’ count number of rows.\n",
    "\n",
    "        --first(), take(n) â†’ preview sample records.\n",
    "\n",
    "*****Aggregations:\n",
    "\n",
    "        --reduceByKey() / groupByKey() for subject-wise or student-wise operations.\n",
    "\n",
    "        --Possibly word countâ€“style demo for understanding RDD basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1773c-ccd0-4126-9321-b50952f8f812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (py310)",
   "language": "python",
   "name": "pyspark310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
