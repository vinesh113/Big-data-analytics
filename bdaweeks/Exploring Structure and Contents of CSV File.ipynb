{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bf1e68-1f24-4fa3-92a0-2fd06b8a9970",
   "metadata": {},
   "source": [
    "Create a DataFrame in PySpark by reading data from a CSV file and explore its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15df5396-8e65-4893-b2fa-4cadf55f005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# Point to Java & Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Progra~1/Java/jdk1.8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:/spark/spark-3.5.7-bin-hadoop3-scala2.13\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"   # if you installed winutils here\n",
    "os.environ[\"PATH\"] += \";C:/spark/spark-3.5.7-bin-hadoop3-scala2.13/bin;C:/hadoop/bin\"\n",
    "\n",
    "# Initialize findspark\n",
    "findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Now build SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV_RDD_Example\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fdbe66-6de3-4650-9966-3cc986021a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://checkhost.local:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CSV_RDD_Example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=CSV_RDD_Example>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd9008-75d3-43d7-ba77-2f1aeed38de0",
   "metadata": {},
   "source": [
    "ðŸ“Š Dataset Overview\n",
    "\n",
    "    --Total Records: 50 students\n",
    "\n",
    "    --Columns: 7 â†’ id, name, age, gender, math, science, english\n",
    "\n",
    "    --No missing values\n",
    "\n",
    "ðŸ‘¥ Demographics\n",
    "\n",
    "    --Age: 18 â€“ 25 years (average â‰ˆ 21.5)\n",
    "\n",
    "    --Gender: 29 Female, 21 Male\n",
    "\n",
    "ðŸ“š Academic Performance\n",
    "\n",
    "**Math:\n",
    "\n",
    "    --Range: 40 â€“ 100\n",
    "\n",
    "    --Mean: 68.9\n",
    "\n",
    "    --Std. Dev.: 17.6 (high variation)\n",
    "\n",
    "**Science:\n",
    "\n",
    "    --Range: 44 â€“ 99\n",
    "\n",
    "    --Mean: 70.2\n",
    "\n",
    "    --Std. Dev.: 14.6 (moderate variation)\n",
    "\n",
    "**English:\n",
    "\n",
    "    --Range: 42 â€“ 100\n",
    "\n",
    "    --Mean: 69.4\n",
    "\n",
    "    --Std. Dev.: 18.7 (highest variation)\n",
    "\n",
    "âœ¨ Key Insights\n",
    "\n",
    "    --Science is the strongest subject on average.\n",
    "\n",
    "    --English has the most variation in performance.\n",
    "\n",
    "    --Students strengths vary â€” performance is not uniform across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5e76b4-7015-49b4-a572-e0b1fa8ac756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    " # Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"BasicDataFrameOps\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52368038-2679-4364-87a7-fc52043b8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 2: Read CSV file into DataFrame\n",
    " df = spark.read.csv(\"students.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa7330e-26b8-4f8c-893b-3491e65582d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 rows ===\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "|  1|  Alice| 20|     F|  66|     92|     44|\n",
      "|  2|    Bob| 20|     M|  82|     52|     77|\n",
      "|  3|Charlie| 22|     F|  43|     57|     76|\n",
      "|  4|  David| 19|     M|  95|     69|     46|\n",
      "|  5|    Eva| 19|     F|  62|     44|     96|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # === Basic Operations ===\n",
    " # 1. View first 5 rows\n",
    " print(\"=== First 5 rows ===\")\n",
    " df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640aa696-51da-435b-8ac6-1c2013550caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- math: integer (nullable = true)\n",
      " |-- science: integer (nullable = true)\n",
      " |-- english: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 2. Print schema (structure of DataFrame)\n",
    " print(\"=== Schema ===\")\n",
    " df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29baef2-a536-4563-8abe-c2a33fa8a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Select name and math columns ===\n",
      "+-------+----+\n",
      "|   name|math|\n",
      "+-------+----+\n",
      "|  Alice|  66|\n",
      "|    Bob|  82|\n",
      "|Charlie|  43|\n",
      "|  David|  95|\n",
      "|    Eva|  62|\n",
      "+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 3. Select specific columns: name and math\n",
    " print(\"=== Select name and math columns ===\")\n",
    "df.select(\"name\", \"math\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a34fcca-016c-4dd8-9481-e213044dd640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Students with math >= 80 ===\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "|  2|   Bob| 20|     M|  82|     52|     77|\n",
      "|  4| David| 19|     M|  95|     69|     46|\n",
      "| 11| Kathy| 25|     M|  85|     71|     89|\n",
      "| 12|   Leo| 24|     M|  97|     84|     83|\n",
      "| 15|Olivia| 18|     M|  87|     90|     87|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 4. Filter students with math >= 80\n",
    " print(\"=== Students with math >= 80 ===\")\n",
    " df.filter(df.math >= 80).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5538f880-6f3e-45d4-8a97-9ca2baf85ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sorted by science (desc) ===\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| 27| Aaron| 25|     F|  81|     99|     44|\n",
      "| 32| Fiona| 22|     F|  48|     96|     48|\n",
      "| 33|George| 22|     M|  66|     95|     84|\n",
      "| 29|  Carl| 22|     F|  53|     92|     52|\n",
      "|  1| Alice| 20|     F|  66|     92|     44|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 5. Sort students by science marks (descending)\n",
    " print(\"=== Sorted by science (desc) ===\")\n",
    " df.orderBy(df.science.desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b25e77cb-df05-48fc-8af0-07456a702562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows: 50\n"
     ]
    }
   ],
   "source": [
    "#6. Count total rows\n",
    "print(\"Total Number of Rows:\",df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789233a7-a648-4e24-a087-66649a56dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'name', 'age', 'gender', 'math', 'science', 'english']\n"
     ]
    }
   ],
   "source": [
    " # 7. Show column names\n",
    " print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740c5eb-8b39-4daa-b189-9949744b71e3",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "PySpark Operations\n",
    "\n",
    "  **Here we performed the following key operations on the DataFrame:\n",
    "\n",
    "    --Data Exploration: Displayed the first 10 rows, printed the schema and data types, and showed summary statistics.\n",
    "\n",
    "    --Column Selection: Selected specific columns like name, age, and math.\n",
    "\n",
    "    --Filtering: Filtered the data to find students with an age of 21 or older and a math score of 70 or higher.\n",
    "\n",
    "    --Data Manipulation: Added a new column named average by calculating the average of the math, science, and english scores.\n",
    "\n",
    "    --Sorting and Filtering: Filtered for students with an average score of 75 or higher and sorted them in descending order.\n",
    "\n",
    "    --Aggregation: Grouped the data by gender to calculate the average scores for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a239168-c7e6-4f56-952c-e11fddfa139c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Stop Spark session\n",
    " # spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbace08-e957-417b-8977-42494e610250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (py310)",
   "language": "python",
   "name": "pyspark310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
