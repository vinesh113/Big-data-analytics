{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d73090-d975-4ce1-ae01-08808d10507c",
   "metadata": {},
   "source": [
    "Implement and demonstrate dataset sampling using the sample() and takeSample() methods in PySpark.(DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f6779c-1b4b-4b85-a1e5-c069ea84cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# Point to Java & Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Progra~1/Java/jdk1.8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:/spark/spark-3.5.7-bin-hadoop3-scala2.13\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"   # if you installed winutils here\n",
    "os.environ[\"PATH\"] += \";C:/spark/spark-3.5.7-bin-hadoop3-scala2.13/bin;C:/hadoop/bin\"\n",
    "\n",
    "# Initialize findspark\n",
    "findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Now build SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV_RDD_Example\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c306763-361e-4b0a-a275-83abee65e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://checkhost.local:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CSV_RDD_Example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=CSV_RDD_Example>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486962b-90ef-45e1-b967-6ed10a846ee7",
   "metadata": {},
   "source": [
    "ðŸ“Š Dataset Overview\n",
    "\n",
    "    --Total Records: 50 students\n",
    "    \n",
    "    --Columns: 7 â†’ id, name, age, gender, math, science, english\n",
    "    \n",
    "    --No missing values\n",
    "    \n",
    "ðŸ‘¥ Demographics\n",
    "\n",
    "    --Age: 18 â€“ 25 years (average â‰ˆ 21.5)\n",
    "    \n",
    "    --Gender: 29 Female, 21 Male\n",
    "    \n",
    "ðŸ“š Academic Performance\n",
    "\n",
    "**Math:\n",
    "\n",
    "    --Range: 40 â€“ 100\n",
    "    \n",
    "    --Mean: 68.9\n",
    "    \n",
    "    --Std. Dev.: 17.6 (high variation)\n",
    "    \n",
    "**Science:\n",
    "\n",
    "    --Range: 44 â€“ 99\n",
    "    \n",
    "    --Mean: 70.2\n",
    "    \n",
    "    --Std. Dev.: 14.6 (moderate variation)\n",
    "    \n",
    "**English:\n",
    "\n",
    "    --Range: 42 â€“ 100\n",
    "    \n",
    "    --Mean: 69.4\n",
    "    \n",
    "    --Std. Dev.: 18.7 (highest variation)\n",
    "\n",
    "Key Insights\n",
    "\n",
    "    --Science is the strongest subject on average.\n",
    "    \n",
    "    --English has the most variation in performance.\n",
    "    \n",
    "    --Students perform differently across subjects (not uniform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0da035-10ff-45f3-b0f1-6fd34d68e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, round, max\n",
    "\n",
    "# Step 1: Start SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StudentsDataFrameExample\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56cfdd3d-63a4-4256-95b1-6ab857d10ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read CSV file (make sure students.csv is in same folder as notebook)\n",
    "df = spark.read.csv(\"students.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a29297-1d9e-4d85-b43e-3e333b8d1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 10 rows ===\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "|  1|  Alice| 20|     F|  66|     92|     44|\n",
      "|  2|    Bob| 20|     M|  82|     52|     77|\n",
      "|  3|Charlie| 22|     F|  43|     57|     76|\n",
      "|  4|  David| 19|     M|  95|     69|     46|\n",
      "|  5|    Eva| 19|     F|  62|     44|     96|\n",
      "|  6|  Frank| 22|     F|  70|     78|     94|\n",
      "|  7|  Grace| 24|     F|  67|     66|     93|\n",
      "|  8|  Henry| 21|     F|  53|     82|     60|\n",
      "|  9|    Ivy| 19|     M|  64|     52|     46|\n",
      "| 10|   Jack| 19|     F|  44|     59|     60|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first 10 rows\n",
    "print(\"=== First 10 rows ===\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761c5a15-54af-493c-a205-465d1ab59145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- math: integer (nullable = true)\n",
      " |-- science: integer (nullable = true)\n",
      " |-- english: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show schema\n",
    "print(\"=== Schema ===\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58a337e-785b-49cb-9531-81af2bed3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Datatypes ===\n",
      "[('id', 'int'), ('name', 'string'), ('age', 'int'), ('gender', 'string'), ('math', 'int'), ('science', 'int'), ('english', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Show datatypes\n",
    "print(\"=== Datatypes ===\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2cf67d-c853-4e62-ba5a-b9f87865b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary statistics ===\n",
      "+-------+------------------+-----+------------------+------+------------------+------------------+-----------------+\n",
      "|summary|                id| name|               age|gender|              math|           science|          english|\n",
      "+-------+------------------+-----+------------------+------+------------------+------------------+-----------------+\n",
      "|  count|                50|   50|                50|    50|                50|                50|               50|\n",
      "|   mean|              25.5| NULL|              21.5|  NULL|             68.94|             70.16|            69.36|\n",
      "| stddev|14.577379737113251| NULL|2.2337851101588404|  NULL|17.609610085034216|14.636214521186957|18.74507826560544|\n",
      "|    min|                 1|Aaron|                18|     F|                40|                44|               42|\n",
      "|    max|                50| Zoey|                25|     M|               100|                99|              100|\n",
      "+-------+------------------+-----+------------------+------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary stats\n",
    "print(\"=== Summary statistics ===\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849dc9f3-703f-444b-b2e9-d2371a72f65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 50\n",
      "Columns: ['id', 'name', 'age', 'gender', 'math', 'science', 'english']\n"
     ]
    }
   ],
   "source": [
    "# Total rows and columns\n",
    "print(\"Total rows:\", df.count())\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8f39ba-5d31-446a-8bae-c305046dc85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Select name, age, and math columns ===\n",
      "+-------+---+----+\n",
      "|   name|age|math|\n",
      "+-------+---+----+\n",
      "|  Alice| 20|  66|\n",
      "|    Bob| 20|  82|\n",
      "|Charlie| 22|  43|\n",
      "|  David| 19|  95|\n",
      "|    Eva| 19|  62|\n",
      "|  Frank| 22|  70|\n",
      "|  Grace| 24|  67|\n",
      "|  Henry| 21|  53|\n",
      "|    Ivy| 19|  64|\n",
      "|   Jack| 19|  44|\n",
      "+-------+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Select specific columns\n",
    "print(\"\\n=== Select name, age, and math columns ===\")\n",
    "df.select(\"name\", \"age\", \"math\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab714ba-49d5-4eeb-adfa-44675ccc20ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Students with age >= 21 and math >= 70 ===\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "|  6|  Frank| 22|     F|  70|     78|     94|\n",
      "| 11|  Kathy| 25|     M|  85|     71|     89|\n",
      "| 12|    Leo| 24|     M|  97|     84|     83|\n",
      "| 14| Nathan| 23|     F|  71|     66|     60|\n",
      "| 22| Victor| 22|     M|  96|     75|     56|\n",
      "| 25|   Yara| 21|     F| 100|     62|     54|\n",
      "| 27|  Aaron| 25|     F|  81|     99|     44|\n",
      "| 30|  Diana| 21|     M|  78|     89|     45|\n",
      "| 35|    Ian| 21|     F|  72|     75|     70|\n",
      "| 36|Jasmine| 21|     F|  90|     58|     71|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Filter students (age >= 21 and math >= 70)\n",
    "print(\"\\n=== Students with age >= 21 and math >= 70 ===\")\n",
    "df.filter((col(\"age\") >= 21) & (col(\"math\") >= 70)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0490d220-3a02-4725-9479-c363e85cc265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset with new column 'average' ===\n",
      "+---+-------+---+------+----+-------+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|average|\n",
      "+---+-------+---+------+----+-------+-------+-------+\n",
      "|  1|  Alice| 20|     F|  66|     92|     44|  67.33|\n",
      "|  2|    Bob| 20|     M|  82|     52|     77|  70.33|\n",
      "|  3|Charlie| 22|     F|  43|     57|     76|  58.67|\n",
      "|  4|  David| 19|     M|  95|     69|     46|   70.0|\n",
      "|  5|    Eva| 19|     F|  62|     44|     96|  67.33|\n",
      "|  6|  Frank| 22|     F|  70|     78|     94|  80.67|\n",
      "|  7|  Grace| 24|     F|  67|     66|     93|  75.33|\n",
      "|  8|  Henry| 21|     F|  53|     82|     60|   65.0|\n",
      "|  9|    Ivy| 19|     M|  64|     52|     46|   54.0|\n",
      "| 10|   Jack| 19|     F|  44|     59|     60|  54.33|\n",
      "+---+-------+---+------+----+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Add a new column: average marks\n",
    "df_with_avg = df.withColumn(\n",
    "    \"average\",\n",
    "    round((col(\"math\") + col(\"science\") + col(\"english\")) / 3, 2)\n",
    ")\n",
    "print(\"\\n=== Dataset with new column 'average' ===\")\n",
    "df_with_avg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344e3ec0-d7a8-4400-9a84-4cad7ca18777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Students with average >= 75 (sorted) ===\n",
      "+---+------+---+------+----+-------+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|average|\n",
      "+---+------+---+------+----+-------+-------+-------+\n",
      "| 12|   Leo| 24|     M|  97|     84|     83|   88.0|\n",
      "| 15|Olivia| 18|     M|  87|     90|     87|   88.0|\n",
      "| 44|  Rita| 24|     M|  90|     82|     88|  86.67|\n",
      "| 11| Kathy| 25|     M|  85|     71|     89|  81.67|\n",
      "| 33|George| 22|     M|  66|     95|     84|  81.67|\n",
      "|  6| Frank| 22|     F|  70|     78|     94|  80.67|\n",
      "| 41| Oscar| 20|     M|  87|     72|     81|   80.0|\n",
      "| 21|   Uma| 19|     F|  89|     70|     76|  78.33|\n",
      "| 37|  Kyle| 21|     M|  57|     86|     92|  78.33|\n",
      "| 39|  Matt| 25|     M|  64|     71|    100|  78.33|\n",
      "+---+------+---+------+----+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Filter students with average >= 75 and sort descending\n",
    "print(\"\\n=== Students with average >= 75 (sorted) ===\")\n",
    "df_with_avg.filter(col(\"average\") >= 75).orderBy(col(\"average\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45283542-d307-4caf-bba2-b669f4a8c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average marks by gender ===\n",
      "+------+--------+-----------+-----------+-----------+\n",
      "|gender|avg_math|avg_science|avg_english|overall_avg|\n",
      "+------+--------+-----------+-----------+-----------+\n",
      "|     F|   63.86|      68.55|      70.55|      67.66|\n",
      "|     M|   75.95|      72.38|      67.71|      72.02|\n",
      "+------+--------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Group by gender and calculate average marks\n",
    "print(\"\\n=== Average marks by gender ===\")\n",
    "df_with_avg.groupBy(\"gender\").agg(\n",
    "    round(avg(\"math\"), 2).alias(\"avg_math\"),\n",
    "    round(avg(\"science\"), 2).alias(\"avg_science\"),\n",
    "    round(avg(\"english\"), 2).alias(\"avg_english\"),\n",
    "    round(avg(\"average\"), 2).alias(\"overall_avg\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52738c28-2aa6-4e4a-9c69-4e6dc6fdc7c5",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "Key Sampling Concepts Demonstrated:\n",
    "\n",
    "    --df.sample(): This method is used to create a new, sampled DataFrame. The notebook demonstrates two variations:\n",
    "\n",
    "    --Without replacement: It creates a sample with 30% of the data, ensuring each row is selected at most once. This is shown by the code\n",
    "        ** df.sample(withReplacement=False, fraction=0.3, seed=42).\n",
    "\n",
    "    --With replacement: It creates a sample with 20% of the data, allowing a row to be selected multiple times. This is shown by the code\n",
    "        ** df.sample(withReplacement=True, fraction=0.2, seed=42).\n",
    "        ** df.rdd.takeSample(): This method returns a local list of rows from the dataset to the driver program. It is useful for                               quickly taking a small, random subset of the data for local inspection. The notebook demonstrates this for 5 rows, both with and without replacement:\n",
    "\n",
    "    --Without replacement: df.rdd.takeSample(False, 5, seed=42) is used to get a list of 5 unique rows.\n",
    "\n",
    "    --With replacement: df.rdd.takeSample(True, 5, seed=42) is used to get a list of 5 rows, with the possibility of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60311fc-a527-4d6b-885c-9eb9f898a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Stop Spark session\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c49c5-1a4a-4004-b5d7-d74813482560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (py310)",
   "language": "python",
   "name": "pyspark310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
